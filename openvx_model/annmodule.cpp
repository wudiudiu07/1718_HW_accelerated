/*
MIT License

Copyright (c) 2018 - 2020 Advanced Micro Devices, Inc. All rights reserved.

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/

/* This file is generated by OpenVX Model Compiler - nnir_to_openvx.py on 2023-04-09T18:47:18.312981-07:00 */

#include "annmodule.h"
#include <VX/vx_khr_nn.h>
#include <stdio.h>

#define ERROR_CHECK_OBJECT(obj) { vx_status status = vxGetStatus((vx_reference)(obj)); if(status != VX_SUCCESS) { vxAddLogEntry((vx_reference)context, status     , "ERROR: failed with status = (%d) at " __FILE__ "#%d\n", status, __LINE__); return status; } }
#define ERROR_CHECK_STATUS(call) { vx_status status = (call); if(status != VX_SUCCESS) { vxAddLogEntry((vx_reference)context, status, "ERROR: failed with status = (%d) at " __FILE__ "#%d\n", status, __LINE__); return status; } }

static vx_status initializeTensor(vx_context context, vx_tensor tensor, FILE * fp, const char * binaryFilename)
{
    vx_enum data_type = VX_TYPE_FLOAT32;
    vx_size num_of_dims = 4, dims[4] = { 1, 1, 1, 1 }, stride[4];
    ERROR_CHECK_STATUS(vxQueryTensor(tensor, VX_TENSOR_DATA_TYPE, &data_type, sizeof(vx_enum)));
    ERROR_CHECK_STATUS(vxQueryTensor(tensor, VX_TENSOR_NUMBER_OF_DIMS, &num_of_dims, sizeof(vx_size)));
    ERROR_CHECK_STATUS(vxQueryTensor(tensor, VX_TENSOR_DIMS, &dims, num_of_dims * sizeof(vx_size)));
    vx_size itemsize = sizeof(float);
    if(data_type == VX_TYPE_UINT8 || data_type == VX_TYPE_INT8) {
        itemsize = sizeof(vx_uint8);
    }
    else if(data_type == VX_TYPE_UINT16 || data_type == VX_TYPE_INT16 || data_type == VX_TYPE_FLOAT16) {
        itemsize = sizeof(vx_uint16);
    }
    else if(data_type == VX_TYPE_INT64) {
        itemsize = sizeof(vx_int64);
    }
    vx_size count = dims[0] * dims[1] * dims[2] * dims[3];

    vx_uint32 h[2] = { 0 };
    fread(h, 1, sizeof(h), fp);
    if(h[0] != 0xf00dd1e1 || (vx_size)h[1] != (count*itemsize)) {
      vxAddLogEntry((vx_reference)tensor, VX_FAILURE, "ERROR: invalid data (magic,size)=(0x%%x,%%d) in %%s at byte position %%d -- expected size is %%ld\n", h[0], h[1], binaryFilename, ftell(fp)-sizeof(h), count*itemsize);
      return VX_FAILURE;
    }

    vx_map_id map_id;
    void * ptr;
    vx_size view_start[num_of_dims] = { 0 };
    vx_size view_end[num_of_dims];
    for(int i = 0; i < num_of_dims; i++)
        view_end[i] = dims[i];
    ERROR_CHECK_STATUS(vxMapTensorPatch(tensor, num_of_dims, view_start, view_end, &map_id, stride, (void **)&ptr, VX_WRITE_ONLY, VX_MEMORY_TYPE_HOST));
    vx_size n = fread(ptr, itemsize, count, fp);
    if(n != count) {
        vxAddLogEntry((vx_reference)tensor, VX_FAILURE, "ERROR: expected char[%%ld], but got char[%%ld] in %%s\n", count*itemsize, n*itemsize, binaryFilename);
        return VX_FAILURE;
    }
    ERROR_CHECK_STATUS(vxUnmapTensorPatch(tensor, map_id));

    return VX_SUCCESS;
}
VX_API_ENTRY vx_status VX_API_CALL annAddToGraph(vx_graph graph, vx_tensor input_ten, vx_tensor out_ten, const char * binaryFilename)
{
    vx_context context = vxGetContext((vx_reference)graph);
    ERROR_CHECK_OBJECT(context);

    // create variables
    vx_size dims_conv1_weight[4] = { 9, 9, 3, 64 };
    vx_tensor conv1_weight = vxCreateTensor(context, 4, dims_conv1_weight, VX_TYPE_FLOAT32, 8);
    ERROR_CHECK_OBJECT(conv1_weight);
    vx_size dims_conv1_bias[1] = { 64 };
    vx_tensor conv1_bias = vxCreateTensor(context, 1, dims_conv1_bias, VX_TYPE_FLOAT32, 8);
    ERROR_CHECK_OBJECT(conv1_bias);
    vx_size dims_conv2_weight[4] = { 1, 1, 64, 32 };
    vx_tensor conv2_weight = vxCreateTensor(context, 4, dims_conv2_weight, VX_TYPE_FLOAT32, 8);
    ERROR_CHECK_OBJECT(conv2_weight);
    vx_size dims_conv2_bias[1] = { 32 };
    vx_tensor conv2_bias = vxCreateTensor(context, 1, dims_conv2_bias, VX_TYPE_FLOAT32, 8);
    ERROR_CHECK_OBJECT(conv2_bias);
    vx_size dims_conv3_weight[4] = { 5, 5, 32, 3 };
    vx_tensor conv3_weight = vxCreateTensor(context, 4, dims_conv3_weight, VX_TYPE_FLOAT32, 8);
    ERROR_CHECK_OBJECT(conv3_weight);
    vx_size dims_conv3_bias[1] = { 3 };
    vx_tensor conv3_bias = vxCreateTensor(context, 1, dims_conv3_bias, VX_TYPE_FLOAT32, 8);
    ERROR_CHECK_OBJECT(conv3_bias);

    // initialize variables
    FILE * fp__variables = fopen(binaryFilename, "rb");
    if(!fp__variables) {
        vxAddLogEntry((vx_reference)context, VX_FAILURE, "ERROR: unable to open: %s\n", binaryFilename);
        return VX_FAILURE;
    }
    { vx_uint32 magic = 0;
      fread(&magic, 1, sizeof(magic), fp__variables);
      if(magic != 0xf00dd1e0) {
        vxAddLogEntry((vx_reference)context, VX_FAILURE, "ERROR: invalid file magic in %s\n", binaryFilename);
        return VX_FAILURE;
      }
    }
    ERROR_CHECK_STATUS(initializeTensor(context, conv1_weight, fp__variables, binaryFilename));
    ERROR_CHECK_STATUS(initializeTensor(context, conv1_bias, fp__variables, binaryFilename));
    ERROR_CHECK_STATUS(initializeTensor(context, conv2_weight, fp__variables, binaryFilename));
    ERROR_CHECK_STATUS(initializeTensor(context, conv2_bias, fp__variables, binaryFilename));
    ERROR_CHECK_STATUS(initializeTensor(context, conv3_weight, fp__variables, binaryFilename));
    ERROR_CHECK_STATUS(initializeTensor(context, conv3_bias, fp__variables, binaryFilename));
    { vx_uint32 magic = 0;
      fread(&magic, 1, sizeof(magic), fp__variables);
      if(magic != 0xf00dd1e2) {
        vxAddLogEntry((vx_reference)context, VX_FAILURE, "ERROR: invalid eoff magic in %s\n", binaryFilename);
        return VX_FAILURE;
      }
      fclose(fp__variables);
    }

    // create local tensors used in graph
    vx_size dims__conv1_Conv_output_0[4] = { 508, 508, 64, 1 };
    vx_tensor _conv1_Conv_output_0 = vxCreateVirtualTensor(graph, 4, dims__conv1_Conv_output_0, VX_TYPE_FLOAT32, 8);
    ERROR_CHECK_OBJECT(_conv1_Conv_output_0);
    vx_size dims__Relu_output_0[4] = { 508, 508, 64, 1 };
    vx_tensor _Relu_output_0 = vxCreateVirtualTensor(graph, 4, dims__Relu_output_0, VX_TYPE_FLOAT32, 8);
    ERROR_CHECK_OBJECT(_Relu_output_0);
    vx_size dims__conv2_Conv_output_0[4] = { 512, 512, 32, 1 };
    vx_tensor _conv2_Conv_output_0 = vxCreateVirtualTensor(graph, 4, dims__conv2_Conv_output_0, VX_TYPE_FLOAT32, 8);
    ERROR_CHECK_OBJECT(_conv2_Conv_output_0);
    vx_size dims__Relu_1_output_0[4] = { 512, 512, 32, 1 };
    vx_tensor _Relu_1_output_0 = vxCreateVirtualTensor(graph, 4, dims__Relu_1_output_0, VX_TYPE_FLOAT32, 8);
    ERROR_CHECK_OBJECT(_Relu_1_output_0);

    // create nodes in graph

    { vx_nn_convolution_params_t conv_params = { 0 };
      conv_params.padding_x = 2;
      conv_params.padding_y = 2;
      conv_params.overflow_policy = VX_CONVERT_POLICY_SATURATE;
      conv_params.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
      conv_params.down_scale_size_rounding = VX_NN_DS_SIZE_ROUNDING_FLOOR;
      conv_params.dilation_x = 0;
      conv_params.dilation_y = 0;
      vx_node node = vxConvolutionLayer(graph, input_ten, conv1_weight, conv1_bias, &conv_params, sizeof(conv_params), _conv1_Conv_output_0);
      ERROR_CHECK_OBJECT(node);
      ERROR_CHECK_STATUS(vxReleaseNode(&node));
    }

    { vx_node node = vxActivationLayer(graph, _conv1_Conv_output_0, VX_NN_ACTIVATION_RELU, 0.0f, 0.0f, _Relu_output_0);
      ERROR_CHECK_OBJECT(node);
      ERROR_CHECK_STATUS(vxReleaseNode(&node));
    }

    { vx_nn_convolution_params_t conv_params = { 0 };
      conv_params.padding_x = 2;
      conv_params.padding_y = 2;
      conv_params.overflow_policy = VX_CONVERT_POLICY_SATURATE;
      conv_params.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
      conv_params.down_scale_size_rounding = VX_NN_DS_SIZE_ROUNDING_FLOOR;
      conv_params.dilation_x = 0;
      conv_params.dilation_y = 0;
      vx_node node = vxConvolutionLayer(graph, _Relu_output_0, conv2_weight, conv2_bias, &conv_params, sizeof(conv_params), _conv2_Conv_output_0);
      ERROR_CHECK_OBJECT(node);
      ERROR_CHECK_STATUS(vxReleaseNode(&node));
    }

    { vx_node node = vxActivationLayer(graph, _conv2_Conv_output_0, VX_NN_ACTIVATION_RELU, 0.0f, 0.0f, _Relu_1_output_0);
      ERROR_CHECK_OBJECT(node);
      ERROR_CHECK_STATUS(vxReleaseNode(&node));
    }

    { vx_nn_convolution_params_t conv_params = { 0 };
      conv_params.padding_x = 2;
      conv_params.padding_y = 2;
      conv_params.overflow_policy = VX_CONVERT_POLICY_SATURATE;
      conv_params.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
      conv_params.down_scale_size_rounding = VX_NN_DS_SIZE_ROUNDING_FLOOR;
      conv_params.dilation_x = 0;
      conv_params.dilation_y = 0;
      vx_node node = vxConvolutionLayer(graph, _Relu_1_output_0, conv3_weight, conv3_bias, &conv_params, sizeof(conv_params), out_ten);
      ERROR_CHECK_OBJECT(node);
      ERROR_CHECK_STATUS(vxReleaseNode(&node));
    }

    // release local tensors
    ERROR_CHECK_STATUS(vxReleaseTensor(&_conv1_Conv_output_0));
    ERROR_CHECK_STATUS(vxReleaseTensor(&_Relu_output_0));
    ERROR_CHECK_STATUS(vxReleaseTensor(&_conv2_Conv_output_0));
    ERROR_CHECK_STATUS(vxReleaseTensor(&_Relu_1_output_0));

    // release initializer tensors
    ERROR_CHECK_STATUS(vxReleaseTensor(&conv1_weight));
    ERROR_CHECK_STATUS(vxReleaseTensor(&conv1_bias));
    ERROR_CHECK_STATUS(vxReleaseTensor(&conv2_weight));
    ERROR_CHECK_STATUS(vxReleaseTensor(&conv2_bias));
    ERROR_CHECK_STATUS(vxReleaseTensor(&conv3_weight));
    ERROR_CHECK_STATUS(vxReleaseTensor(&conv3_bias));

    return VX_SUCCESS;
}
